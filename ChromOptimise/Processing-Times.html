<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ChromOptimise/Processing-Times" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Processing times | ChromOptimise</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://sof202.github.io/ChromOptimise/img/dna.png"><meta data-rh="true" name="twitter:image" content="https://sof202.github.io/ChromOptimise/img/dna.png"><meta data-rh="true" property="og:url" content="https://sof202.github.io/ChromOptimise/ChromOptimise/Processing-Times"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Processing times | ChromOptimise"><meta data-rh="true" name="description" content="SLURM workload manager has the feature of introducing a maximum wall time into each script. The default maximum wall time is set in the #SBATCH section of each script and can be overridden when setting the --time option when using sbatch. If the time of execution for a script exceeds this maximum wall time, it will terminate early. This is useful as it helps with workload management on HPCs that a large number of users have access to, and also reduces the effects of non-halting programs."><meta data-rh="true" property="og:description" content="SLURM workload manager has the feature of introducing a maximum wall time into each script. The default maximum wall time is set in the #SBATCH section of each script and can be overridden when setting the --time option when using sbatch. If the time of execution for a script exceeds this maximum wall time, it will terminate early. This is useful as it helps with workload management on HPCs that a large number of users have access to, and also reduces the effects of non-halting programs."><link data-rh="true" rel="icon" href="/ChromOptimise/img/dna.ico"><link data-rh="true" rel="canonical" href="https://sof202.github.io/ChromOptimise/ChromOptimise/Processing-Times"><link data-rh="true" rel="alternate" href="https://sof202.github.io/ChromOptimise/ChromOptimise/Processing-Times" hreflang="en"><link data-rh="true" rel="alternate" href="https://sof202.github.io/ChromOptimise/ChromOptimise/Processing-Times" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ChromOptimise/assets/css/styles.e3ab61ce.css">
<script src="/ChromOptimise/assets/js/runtime~main.7f046562.js" defer="defer"></script>
<script src="/ChromOptimise/assets/js/main.62103c36.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ChromOptimise/"><div class="navbar__logo"><img src="/ChromOptimise/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ChromOptimise/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">ChromOptimise</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ChromOptimise/">Documentation</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sof202/ChromOptimise" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ChromOptimise/">Welcome to the ChromOptimise wiki!</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/ChromOptimise/category/chromoptimise-documentation">ChromOptimise Documentation</a><button aria-label="Collapse sidebar category &#x27;ChromOptimise Documentation&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/ChromHMM-overview">ChromHMM overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/Configuration-Files-Setup">Configuration files setup</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/Pipeline-Explanation">Pipeline explanation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/Supplementary-pipeline-explanation">Supplementary pipeline explanation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/Factors-that-affect-the-output">Factors that affect the output</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ChromOptimise/ChromOptimise/Processing-Times">Processing times</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/Memory-Profiling">Memory profiling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ChromOptimise/ChromOptimise/SLURM-Workload-Manager-Information">SLURM information</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ChromOptimise/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/ChromOptimise/category/chromoptimise-documentation"><span itemprop="name">ChromOptimise Documentation</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Processing times</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Processing times</h1>
<p>SLURM workload manager has the feature of introducing a maximum wall time into each script. The default maximum wall time is set in the <code>#SBATCH</code> section of each script and can be overridden when setting the <code>--time</code> option when using <code>sbatch</code>. If the time of execution for a script exceeds this maximum wall time, it will terminate early. This is useful as it helps with workload management on HPCs that a large number of users have access to, and also reduces the effects of non-halting programs.
<br>
<!-- -->Using bash builtins and time utilities, we were able to create estimates on how long each script is expected to take depending on the inputs and complexity of information.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="contents">Contents<a href="#contents" class="hash-link" aria-label="Direct link to Contents" title="Direct link to Contents">​</a></h2>
<ul>
<li><a href="#general-cpu-information-which-testing-was-conducted-on">General CPU information which testing was conducted on</a></li>
<li><a href="#0_downloadblueprintsh">0_DownloadBluePrint.sh</a></li>
<li><a href="#1_movingfilestosingledirectorysh">1_MovingFilesToSingleDirectory.sh</a></li>
<li><a href="#2_batch_processbamfilessh">2_batch_ProcessBamFiles.sh</a></li>
<li><a href="#3_subsamplebamfilessh">3_SubsampleBamFiles.sh</a></li>
<li><a href="#4_binarizebamfilessh">4_BinarizeBamFiles.sh</a></li>
<li><a href="#5_batch_createincrementalmodelssh">5_batch_CreateIncrementalModels.sh</a></li>
<li><a href="#6_optimalnumberofstatessh">6_OptimalNumberOfStates.sh</a></li>
<li><a href="#generate_big_modelsh">Generate_Big_Model.sh</a></li>
<li><a href="#generate_redundancy_metrics_plotssh">Generate_Redundancy_Metrics_Plots.sh</a></li>
<li><a href="#comparemodelssh">CompareModels.sh</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-cpu-information-which-testing-was-conducted-on">General CPU information which testing was conducted on<a href="#general-cpu-information-which-testing-was-conducted-on" class="hash-link" aria-label="Direct link to General CPU information which testing was conducted on" title="Direct link to General CPU information which testing was conducted on">​</a></h2>
<p>Note that processing times are likely to vary across systems, the scripts were tested on a high performance cluster (HPC) that is split into several compute nodes. Each script was ran on a compute node which have the following properties:</p>
<ul>
<li>CPUs -&gt; 16</li>
<li>Sockets -&gt; 2</li>
<li>Cores per socket -&gt; 8</li>
<li>Threads per core -&gt; 1</li>
<li>CPU clock speed -&gt; 2.601 GHz (max)</li>
<li>CPU model -&gt; Intel(R) Xeon(R) CPU E5-2640 v3</li>
<li>Cache<!-- -->
<ul>
<li>L1i (information) -&gt; 32K</li>
<li>L1d (data) -&gt; 32K</li>
<li>L2 -&gt; 256K</li>
<li>L3 -&gt; 20 MB</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0_downloadblueprintsh">0_DownloadBluePrint.sh<a href="#0_downloadblueprintsh" class="hash-link" aria-label="Direct link to 0_DownloadBluePrint.sh" title="Direct link to 0_DownloadBluePrint.sh">​</a></h2>
<p>The time taken to download files using pyega3 will of course depend on internet speed, size of files and number of files being downloaded. The former of these three makes it difficult to create well informed estimates for the run time of this script. In testing, the internet speed did not appear throttled and was consistent across file downloads.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1_movingfilestosingledirectorysh">1_MovingFilesToSingleDirectory.sh<a href="#1_movingfilestosingledirectorysh" class="hash-link" aria-label="Direct link to 1_MovingFilesToSingleDirectory.sh" title="Direct link to 1_MovingFilesToSingleDirectory.sh">​</a></h2>
<p>Moving files on Linux systems is generally very fast even when files are large or abundant. The main souce of processing time in this script is the <code>find</code> command. Depending on how many files exist in the main directory you are working with, the processing time for <code>find</code> can vary as more files need to be checked.
<br>
<!-- -->Regardless, in previous tests moving 130 files (each being 1-2 GB) amongst ~1000 total files took roughly one minute. It is unlikely that the processing time will ever exceed the default maximum wall time set in the <code>#SBATCH</code> parameters at the top of this script.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2_batch_processbamfilessh">2_batch_ProcessBamFiles.sh<a href="#2_batch_processbamfilessh" class="hash-link" aria-label="Direct link to 2_batch_ProcessBamFiles.sh" title="Direct link to 2_batch_ProcessBamFiles.sh">​</a></h2>
<p>The processing time for this script mainly depends on the sizes of the files that are being processed. In tests thus far, the main contributor to computational time comes from <code>samtools sort</code> and appears to have a linear relationship with file size.
<br>
<!-- -->In testing, the following was observed:</p>
<ul>
<li>Processing a ~1.1 GB file took ~10 minutes</li>
<li>Processing a ~1.4 GB file took ~12 minutes</li>
<li>Processing a ~1.8 GB file took ~16 minutes</li>
<li>Processing a ~2.1 GB file took ~19 minutes</li>
</ul>
<p>The conclusion was made that one should expect that the processing time would be roughly:
<br>
<!-- -->[9 * file size (in GB)] minutes.
<br>
<!-- -->Additionally, it&#x27;s important to note that this script is designed to be executed as an array through the SLURM workload manager. Therefore, the processing time is likely to vary depending on the number of cores assigned to each task in the array. Further note that if the size of the array is larger than the number of files being processed, all files will be processed by the highest indexed array element (causing slow down).
<br>
<!-- -->When applying an array of size 4, the following was observed:</p>
<ul>
<li>Processing ~272 GB of files took ~ 11 hours and 45 minutes</li>
<li>Processing ~228 GB of files took ~ 9 hours and 53 minutes</li>
<li>Processing ~263 GB of files took ~ 10 hours and 47 minutes</li>
</ul>
<p>This to some extent supports the above claim for the processing time being linear. It is unlikely that using an array size of 4 will result in exactly 4 times faster processing time. Therefore, it is difficult to support the processing time equation previously given using these tests.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3_subsamplebamfilessh">3_SubsampleBamFiles.sh<a href="#3_subsamplebamfilessh" class="hash-link" aria-label="Direct link to 3_SubsampleBamFiles.sh" title="Direct link to 3_SubsampleBamFiles.sh">​</a></h2>
<p>This script&#x27;s largest contributor to computational time is <code>samtools merge</code>. Depending on the number of files and size of said files, the time taken can vary dramatically.
<br>
<!-- -->In testing, the following was observed:</p>
<p>Using a 50% sampling rate:</p>
<table><thead><tr><th>Number of files</th><th>Average file size (GB)</th><th>time (minutes)</th></tr></thead><tbody><tr><td>2</td><td>3.5</td><td>4</td></tr><tr><td>2</td><td>6.5</td><td>7</td></tr><tr><td>133</td><td>8.3</td><td>906</td></tr><tr><td>171</td><td>6.2</td><td>1010</td></tr><tr><td>176</td><td>7.6</td><td>1271</td></tr></tbody></table>
<p>Using a 100% sampling rate:</p>
<table><thead><tr><th>Number of files</th><th>Average file size (GB)</th><th>time (minutes)</th></tr></thead><tbody><tr><td>133</td><td>8.3</td><td>909</td></tr><tr><td>171</td><td>6.2</td><td>1186</td></tr><tr><td>176</td><td>7.6</td><td>1366</td></tr></tbody></table>
<p>Currently this shows a linear relationship with total file size. There is not enough information to determine the effect that the sampling rate has on the processing time (though it is likely to be minimal).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4_binarizebamfilessh">4_BinarizeBamFiles.sh<a href="#4_binarizebamfilessh" class="hash-link" aria-label="Direct link to 4_BinarizeBamFiles.sh" title="Direct link to 4_BinarizeBamFiles.sh">​</a></h2>
<p>The processing time for this script is of course mainly taken up by ChromHMM&#x27;s <code>BinarizeBam</code> command. This command will generally take up more time if more data is inputted and if a smaller bin size is used.
<br>
<!-- -->In testing, the following was observed:</p>
<ul>
<li>Using 17 GB of .bam files:<!-- -->
<ul>
<li>Using a bin size of 200bp took ~4 minutes</li>
</ul>
</li>
<li>Using 3730 GB of .bam files:<!-- -->
<ul>
<li>Using a bin size of 200bp took 11 hours and 52 minutes</li>
<li>Using a bin size of 400bp took 11 hours and 47 minutes</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5_batch_createincrementalmodelssh">5_batch_CreateIncrementalModels.sh<a href="#5_batch_createincrementalmodelssh" class="hash-link" aria-label="Direct link to 5_batch_CreateIncrementalModels.sh" title="Direct link to 5_batch_CreateIncrementalModels.sh">​</a></h2>
<p>This script&#x27;s largest contributor to computational time is ChromHMM&#x27;s <code>LearnModel</code> command. This command will take up more time if the bin size was chosen to be smaller in 4_BinarizeBamFiles.sh (leading to a larger total size of binary signal files) and if the number of states to be used in the model increases.
<br>
<!-- -->From the <a href="https://compbio.mit.edu/ChromHMM/ChromHMM_manual.pdf" target="_blank" rel="noopener noreferrer">user manual</a> and the <a href="https://github.com/jernst98/ChromHMM/blob/master/edu/mit/compbio/ChromHMM/ChromHMM.java" target="_blank" rel="noopener noreferrer">source code</a>, it is clear that the model training is completed via the forward-backwards algorithm and the Baum-Welch algorithm. These algorithms are standard in hidden Markov model training and likely take up the majority of processing time.
<br>
<!-- -->From a <a href="https://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf" target="_blank" rel="noopener noreferrer">resource</a> sent by one of the creators, Jason Ernst, these algorithms have a computational complexity of O(N<sup>2</sup>T). Where N is the number of states in the model and T is the total number of observations (proportional to sizes of binary files).</p>
<p><strong>Note</strong>: Although the algorithms mentioned have computational complexity of O(N<sup>2</sup>T), this doesn&#x27;t serve as the complete picture. By default, ChromHMM will terminate once the change in the likelihood function is below 0.001. The number of iterations it takes to reach this point can vary massively between models and datasets. The maximum number of iterations (by default) is 200. Keep this maximum iteration number into account when considering processing times.
<br>
<!-- -->In testing, the following was observed:</p>
<p>For 1.6 MB of binary data (400bp bins, 3 marks)</p>
<table><thead><tr><th>Number of states</th><th>Average time per iteration (seconds)</th></tr></thead><tbody><tr><td>2</td><td>1.27</td></tr><tr><td>3</td><td>1.31</td></tr><tr><td>4</td><td>1.71</td></tr><tr><td>5</td><td>2.17</td></tr><tr><td>6</td><td>2.66</td></tr><tr><td>7</td><td>3.49</td></tr><tr><td>8</td><td>4.76</td></tr></tbody></table>
<p>It is important to note that this script is designed to be executed as an array through the SLURM workload manager. Therefore, the processing time is likely to vary depending on the number of cores assigned to each task in the array. Further note that if the size of the array is larger than the number of models to learn, all models will be learnt by the highest indexed array element (causing significant slow down).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6_optimalnumberofstatessh">6_OptimalNumberOfStates.sh<a href="#6_optimalnumberofstatessh" class="hash-link" aria-label="Direct link to 6_OptimalNumberOfStates.sh" title="Direct link to 6_OptimalNumberOfStates.sh">​</a></h2>
<p>This script makes use of an R script that is inside of a loop. However, the Rscript has very little computational complexity and so the script is usually very fast. In previous tests with 8 state models, the script took ~14 seconds. It is unlikely that this script will ever exceed the default wall time set in the <code>#SBATCH</code> parameters at the top of the script.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="generate_big_modelsh">Generate_Big_Model.sh<a href="#generate_big_modelsh" class="hash-link" aria-label="Direct link to Generate_Big_Model.sh" title="Direct link to Generate_Big_Model.sh">​</a></h2>
<p>Computational time for this script follows the same logic as <a href="#5_batch_createincrementalmodelssh">5_batch_CreateIncrementalModels.sh</a>. The main contributor to computational time is ChromHMM&#x27;s <code>LearnModel</code> command, only this time the models are likely to be much larger. As a result expect the processing time to be very long if a high number of states is to be used.
<br>
<!-- -->In testing, the following was observed:</p>
<ul>
<li>For ~1 MB of binary data (200bp bins)<!-- -->
<ul>
<li>20 states took 1 hour 48 minutes</li>
<li>30 states took 3 hours 48 minutes</li>
<li>40 states took 7 hours 9 minutes</li>
<li>60 states took 14 hours 36 minutes</li>
<li>70 states took 19 hours 18 minutes</li>
<li>80 states took 25 hours 34 minutes</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="generate_redundancy_metrics_plotssh">Generate_Redundancy_Metrics_Plots.sh<a href="#generate_redundancy_metrics_plotssh" class="hash-link" aria-label="Direct link to Generate_Redundancy_Metrics_Plots.sh" title="Direct link to Generate_Redundancy_Metrics_Plots.sh">​</a></h2>
<p>This script calls two R scripts that make one plot each. The amount of data that is parsed into them is very small (unless the models have hundreds of states). Therefore, despite R being relatively slow, this script should never take any longer than one minute. In testing, processing a model with 80 states took 12 seconds.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="comparemodelssh">CompareModels.sh<a href="#comparemodelssh" class="hash-link" aria-label="Direct link to CompareModels.sh" title="Direct link to CompareModels.sh">​</a></h2>
<p>Most computational time is accredited to ChromHMM&#x27;s <code>CompareModels</code> command. However, this command does not require a large amount of time to run. In tests, comparing models to a model of 8 states (then to 7 states, 6, 5 etc.) took only 18 seconds. Therefore it is unlikely that this script will ever exceed the default wall time set in the <code>#SBATCH</code> parameters at the top of the script.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ChromOptimise/ChromOptimise/Factors-that-affect-the-output"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Factors that affect the output</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ChromOptimise/ChromOptimise/Memory-Profiling"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Memory profiling</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#contents" class="table-of-contents__link toc-highlight">Contents</a></li><li><a href="#general-cpu-information-which-testing-was-conducted-on" class="table-of-contents__link toc-highlight">General CPU information which testing was conducted on</a></li><li><a href="#0_downloadblueprintsh" class="table-of-contents__link toc-highlight">0_DownloadBluePrint.sh</a></li><li><a href="#1_movingfilestosingledirectorysh" class="table-of-contents__link toc-highlight">1_MovingFilesToSingleDirectory.sh</a></li><li><a href="#2_batch_processbamfilessh" class="table-of-contents__link toc-highlight">2_batch_ProcessBamFiles.sh</a></li><li><a href="#3_subsamplebamfilessh" class="table-of-contents__link toc-highlight">3_SubsampleBamFiles.sh</a></li><li><a href="#4_binarizebamfilessh" class="table-of-contents__link toc-highlight">4_BinarizeBamFiles.sh</a></li><li><a href="#5_batch_createincrementalmodelssh" class="table-of-contents__link toc-highlight">5_batch_CreateIncrementalModels.sh</a></li><li><a href="#6_optimalnumberofstatessh" class="table-of-contents__link toc-highlight">6_OptimalNumberOfStates.sh</a></li><li><a href="#generate_big_modelsh" class="table-of-contents__link toc-highlight">Generate_Big_Model.sh</a></li><li><a href="#generate_redundancy_metrics_plotssh" class="table-of-contents__link toc-highlight">Generate_Redundancy_Metrics_Plots.sh</a></li><li><a href="#comparemodelssh" class="table-of-contents__link toc-highlight">CompareModels.sh</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 ChromOptimise, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>