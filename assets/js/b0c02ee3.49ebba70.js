"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[4943],{2599:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>h,contentTitle:()=>r,default:()=>m,frontMatter:()=>t,metadata:()=>l,toc:()=>a});var i=s(5893),o=s(1151);const t={sidebar_position:6},r="Processing times",l={id:"ChromOptimise/Processing-Times",title:"Processing times",description:"SLURM workload manager has the feature of introducing a maximum wall time into",source:"@site/docs/ChromOptimise/Processing-Times.md",sourceDirName:"ChromOptimise",slug:"/ChromOptimise/Processing-Times",permalink:"/ChromOptimise/ChromOptimise/Processing-Times",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"documentationSidebar",previous:{title:"Factors that affect the output",permalink:"/ChromOptimise/ChromOptimise/Factors-that-affect-the-output"},next:{title:"Memory profiling",permalink:"/ChromOptimise/ChromOptimise/Memory-Profiling"}},h={},a=[{value:"General CPU information which testing was conducted on",id:"general-cpu-information-which-testing-was-conducted-on",level:2},{value:"1_BinarizeBamFiles.sh",id:"1_binarizebamfilessh",level:2},{value:"2_batch_CreateIncrementalModels.sh",id:"2_batch_createincrementalmodelssh",level:2},{value:"3_OptimalNumberOfStates.sh",id:"3_optimalnumberofstatessh",level:2},{value:"4_ReferenceLDSCore.sh",id:"4_referenceldscoresh",level:2},{value:"5_PartitionedHeritability.sh",id:"5_partitionedheritabilitysh",level:2},{value:"Generate_Big_Model.sh",id:"generate_big_modelsh",level:2}];function c(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"processing-times",children:"Processing times"}),"\n",(0,i.jsxs)(n.p,{children:["SLURM workload manager has the feature of introducing a maximum wall time into\neach script. The default maximum wall time is set in the ",(0,i.jsx)(n.code,{children:"#SBATCH"})," section of\neach script and can be overridden when setting the ",(0,i.jsx)(n.code,{children:"--time"})," option when using\n",(0,i.jsx)(n.code,{children:"sbatch"}),". If the time of execution for a script exceeds this maximum wall time,\nit will terminate early. This is useful as it helps with workload management on\nHPCs that a large number of users have access to, and also reduces the effects\nof non-halting programs."]}),"\n",(0,i.jsx)(n.p,{children:"Using bash builtins and time utilities, we were able to create estimates on how\nlong each script is expected to take depending on the inputs and complexity of\ninformation."}),"\n",(0,i.jsx)(n.h2,{id:"general-cpu-information-which-testing-was-conducted-on",children:"General CPU information which testing was conducted on"}),"\n",(0,i.jsx)(n.p,{children:"Note that processing times are likely to vary across systems, the scripts were\ntested on a high performance cluster (HPC) that is split into several compute\nnodes. Each script was ran on a compute node which have the following\nproperties:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"CPUs -> 16"}),"\n",(0,i.jsx)(n.li,{children:"Sockets -> 2"}),"\n",(0,i.jsx)(n.li,{children:"Cores per socket -> 8"}),"\n",(0,i.jsx)(n.li,{children:"Threads per core -> 1"}),"\n",(0,i.jsx)(n.li,{children:"CPU clock speed -> 2.601 GHz (max)"}),"\n",(0,i.jsx)(n.li,{children:"CPU model -> Intel(R) Xeon(R) CPU E5-2640 v3"}),"\n",(0,i.jsxs)(n.li,{children:["Cache","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"L1i (information) -> 32K"}),"\n",(0,i.jsx)(n.li,{children:"L1d (data) -> 32K"}),"\n",(0,i.jsx)(n.li,{children:"L2 -> 256K"}),"\n",(0,i.jsx)(n.li,{children:"L3 -> 20 MB"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"1_binarizebamfilessh",children:"1_BinarizeBamFiles.sh"}),"\n",(0,i.jsxs)(n.p,{children:["The processing time for this script is of course mainly taken up by ChromHMM's\n",(0,i.jsx)(n.code,{children:"BinarizeBam"})," command. This command will generally take up more time if more\ndata is inputted and if a smaller bin size is used."]}),"\n",(0,i.jsx)(n.p,{children:"In testing, the following was observed:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Using 17 GB of .bam files:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Using a bin size of 200bp took ~4 minutes"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Using 3730 GB of .bam files:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Using a bin size of 200bp took 11 hours and 52 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Using a bin size of 400bp took 11 hours and 47 minutes"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"2_batch_createincrementalmodelssh",children:"2_batch_CreateIncrementalModels.sh"}),"\n",(0,i.jsxs)(n.p,{children:["This script's largest contributor to computational time is ChromHMM's\n",(0,i.jsx)(n.code,{children:"LearnModel"})," command. This command will take up more time if the bin size was\nchosen to be smaller in 4_BinarizeBamFiles.sh (leading to a larger total size\nof binary signal files) and if the number of states to be used in the model\nincreases. \\ From the ",(0,i.jsx)(n.a,{href:"https://compbio.mit.edu/ChromHMM/ChromHMM_manual.pdf",children:"user manual"})," and the\n",(0,i.jsx)(n.a,{href:"https://github.com/jernst98/ChromHMM/blob/master/edu/mit/compbio/ChromHMM/ChromHMM.java",children:"source code"}),",\nit is clear that the model training is completed via the forward-backwards\nalgorithm and the Baum-Welch algorithm. These algorithms are standard in hidden\nMarkov model training and likely take up the majority of processing time. ",(0,i.jsx)(n.br,{}),"\n","From a ",(0,i.jsx)(n.a,{href:"https://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf",children:"resource"})," sent by one\nof the creators, Jason Ernst, these algorithms have a computational complexity\nof O(N",(0,i.jsx)("sup",{children:"2"}),"T). Where N is the number of states in the model and T is the\ntotal number of observations (proportional to sizes of binary files)."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note"}),": Although the algorithms mentioned have computational complexity of\nO(N",(0,i.jsx)("sup",{children:"2"}),"T), this doesn't serve as the complete picture. By default,\nChromHMM will terminate once the change in the likelihood function is below\n001. The number of iterations it takes to reach this point can vary massively\nbetween models and datasets. The maximum number of iterations (by default) is\n200. Keep this maximum iteration number into account when considering\nprocessing times. \\ In testing, the following was observed:"]}),"\n",(0,i.jsx)(n.p,{children:"For 1.6 MB of binary data (400bp bins, 3 marks)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Number of states"}),(0,i.jsx)(n.th,{children:"Average time per iteration (seconds)"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"2"}),(0,i.jsx)(n.td,{children:"1.27"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"3"}),(0,i.jsx)(n.td,{children:"1.31"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4"}),(0,i.jsx)(n.td,{children:"1.71"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"5"}),(0,i.jsx)(n.td,{children:"2.17"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"6"}),(0,i.jsx)(n.td,{children:"2.66"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"7"}),(0,i.jsx)(n.td,{children:"3.49"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"8"}),(0,i.jsx)(n.td,{children:"4.76"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"It is important to note that this script is designed to be executed as an array\nthrough the SLURM workload manager. Therefore, the processing time is likely to\nvary depending on the number of cores assigned to each task in the array.\nFurther note that if the size of the array is larger than the number of models\nto learn, all models will be learnt by the highest indexed array element\n(causing significant slow down)."}),"\n",(0,i.jsx)(n.h2,{id:"3_optimalnumberofstatessh",children:"3_OptimalNumberOfStates.sh"}),"\n",(0,i.jsxs)(n.p,{children:["This script makes use of an R script that is inside of a loop. However, the\nRscript has very little computational complexity and so the script is usually\nvery fast. In previous tests with 8 state models, the script took ~14 seconds.\nIt is unlikely that this script will ever exceed the default wall time set in\nthe ",(0,i.jsx)(n.code,{children:"#SBATCH"})," parameters at the top of the script."]}),"\n",(0,i.jsx)(n.h2,{id:"4_referenceldscoresh",children:"4_ReferenceLDSCore.sh"}),"\n",(0,i.jsx)(n.p,{children:"This script will take roughly the same amount of time regardless of the number\nof states in your model. In testing, the following times were found for the\nSNP assignment R script:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Chromosome 1 took: 964 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 2 took: 1163 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 3 took: 757 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 4 took: 804 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 5 took: 698 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 6 took: 733 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 7 took: 637 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 8 took: 597 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 9 took: 490 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 10 took: 562 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 11 took: 530 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 12 took: 504 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 13 took: 387 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 14 took: 354 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 15 took: 299 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 16 took: 345 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 17 took: 281 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 18 took: 313 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 19 took: 239 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 20 took: 223 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 21 took: 136 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 22 took: 138 seconds"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"For the calculation of LDscores:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Chromosome 1 took: 11 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 2 took: 13 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 3 took: 11 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 4 took: 11 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 5 took: 9 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 6 took: 10 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 7 took: 9 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 8 took: 9 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 9 took: 6 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 10 took: 7 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 11 took: 7 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 12 took: 7 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 13 took: 5 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 14 took: 5 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 15 took: 4 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 16 took: 5 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 17 took: 3 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 18 took: 4 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 19 took: 3 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 20 took: 3 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 21 took: 2 minutes"}),"\n",(0,i.jsx)(n.li,{children:"Chromosome 22 took: 2 minutes"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"5_partitionedheritabilitysh",children:"5_PartitionedHeritability.sh"}),"\n",(0,i.jsxs)(n.p,{children:["This script will linearly increase in time with each additional gwas trait\nconsidered. The effect of having more annotations seems to be minimal however\n(more annotations only appears to increase\n",(0,i.jsx)(n.a,{href:"/ChromOptimise/ChromOptimise/Memory-Profiling",children:"memory requirements"}),"). In testing, for 58 annotations\n(8 state annotations), this script took on average 6 minutes and 30 seconds\nfor each gwas trait (with a high of 7.01 minutes and a low of 6.05 minutes)"]}),"\n",(0,i.jsx)(n.h2,{id:"generate_big_modelsh",children:"Generate_Big_Model.sh"}),"\n",(0,i.jsxs)(n.p,{children:["Computational time for this script follows the same logic as\n",(0,i.jsx)(n.a,{href:"#2_batch_createincrementalmodelssh",children:"2_batch_CreateIncrementalModels.sh"}),". The\nmain contributor to computational time is ChromHMM's ",(0,i.jsx)(n.code,{children:"LearnModel"})," command, only\nthis time the models are likely to be much larger. As a result expect the\nprocessing time to be very long if a high number of states is to be used."]}),"\n",(0,i.jsx)(n.p,{children:"In testing, the following was observed:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["For ~1 MB of binary data (200bp bins)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"20 states took 1 hour 48 minutes"}),"\n",(0,i.jsx)(n.li,{children:"30 states took 3 hours 48 minutes"}),"\n",(0,i.jsx)(n.li,{children:"40 states took 7 hours 9 minutes"}),"\n",(0,i.jsx)(n.li,{children:"60 states took 14 hours 36 minutes"}),"\n",(0,i.jsx)(n.li,{children:"70 states took 19 hours 18 minutes"}),"\n",(0,i.jsx)(n.li,{children:"80 states took 25 hours 34 minutes"}),"\n"]}),"\n"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},1151:(e,n,s)=>{s.d(n,{Z:()=>l,a:()=>r});var i=s(7294);const o={},t=i.createContext(o);function r(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);